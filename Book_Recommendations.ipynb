{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import gzip\n",
    "from collections import defaultdict\n",
    "import math\n",
    "import scipy.optimize\n",
    "import numpy\n",
    "import string\n",
    "import random\n",
    "import string\n",
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readGz(path):\n",
    "    for l in gzip.open(path, 'rt'):\n",
    "        yield eval(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readCSV(path):\n",
    "    f = gzip.open(path, 'rt')\n",
    "    f.readline()\n",
    "    for l in f:\n",
    "        u,b,r = l.strip().split(',')\n",
    "        r = int(r)\n",
    "        yield u,b,r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "allRatings = []\n",
    "for l in readCSV(\"train_Interactions.csv.gz\"):\n",
    "    allRatings.append(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = allRatings[:190000]\n",
    "valid = allRatings[190000:]\n",
    "ratingsPerUser = defaultdict(list)\n",
    "ratingsPerItem = defaultdict(list)\n",
    "usersPerBook = defaultdict(set)\n",
    "booksPerUser = defaultdict(set)\n",
    "for u,b,r in train:\n",
    "    ratingsPerUser[u].append((b,r))\n",
    "    ratingsPerItem[b].append((u,r))\n",
    "    usersPerBook[b].add(u)\n",
    "    booksPerUser[u].add(b)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# useful sets\n",
    "ubdict = defaultdict(list)\n",
    "userSet = set()\n",
    "bookSet = set()\n",
    "readSet = set()\n",
    "\n",
    "for u,b,r in allRatings:\n",
    "    userSet.add(u)\n",
    "    bookSet.add(b)\n",
    "    readSet.add((u,b))\n",
    "    ubdict[u].append(b)\n",
    "\n",
    "lUserSet = list(userSet)\n",
    "lBookSet = list(bookSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get(val):\n",
    "    m=[]\n",
    "    m.append(val[0])\n",
    "    m.append(val[1])\n",
    "    m.append(True)\n",
    "    #m.append(val[2])\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "posvalid =[get(v) for v in valid]\n",
    "postrain =[get(v) for v in train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['u35176258', 'b30592470', True]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posvalid[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1 Adding Negative labels to Validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def negbook(val):\n",
    "    neg = []\n",
    "    while len(neg)==0:\n",
    "        b= random.choice(lBookSet)\n",
    "        if b not in ubdict[val[0]]:\n",
    "            neg.append(val[0])\n",
    "            neg.append(b)\n",
    "            neg.append(False)         \n",
    "    return neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "negvalid = [negbook(v) for v in valid]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_valid = posvalid + negvalid\n",
    "#random.shuffle(total_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = [v[2] for v in total_valid]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining Jaccard,cosine,Popularity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Using logistic regression to combine the jaccard and most popularity,cosine \n",
    "negtrain = [negbook(v) for v in train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_train = postrain + negtrain\n",
    "#random.shuffle(total_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "380000"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(total_train)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "unit_train = []\n",
    "for u,b,_ in total_train:\n",
    "    unit_train.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "bookCount = defaultdict(int)\n",
    "totalRead = 0\n",
    "\n",
    "for user,book,_ in train:\n",
    "  bookCount[book] += 1\n",
    "  totalRead += 1\n",
    "\n",
    "mostPopular = [(bookCount[x], x) for x in bookCount]\n",
    "mostPopular.sort()\n",
    "mostPopular.reverse()\n",
    "\n",
    "return1 = set()\n",
    "count = 0\n",
    "for ic, i in mostPopular:\n",
    "  count += ic\n",
    "  return1.add(i)\n",
    "  if count > totalRead*0.58: break\n",
    "    \n",
    "    \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_pre = []\n",
    "for u,b,_ in total_train:\n",
    "    if b in return1:\n",
    "        pop_pre.append(True)\n",
    "    else:\n",
    "        pop_pre.append(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Jaccard(s1, s2):\n",
    "    numer = len(s1.intersection(s2))\n",
    "    denom = len(s1.union(s2))\n",
    "    if denom > 0:\n",
    "        return numer/denom\n",
    "    return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mostSimilarFast(u,b):\n",
    "    similarities = []   \n",
    "    #b1- all users who have read b\n",
    "    users = usersPerBook[b]\n",
    "   \n",
    "\n",
    "    for i2 in booksPerUser[u]:\n",
    "        if i2 == b: continue\n",
    "        sim = Jaccard(users, usersPerBook[i2])\n",
    "        similarities.append((sim))\n",
    "    similarities.sort(reverse=True)\n",
    "    for x in similarities[:1]:\n",
    "        if x > 0:\n",
    "            return x\n",
    "    return 0\n",
    "                            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "Jac_pre = []\n",
    "for u,b,_ in total_train:\n",
    "    temp = mostSimilarFast(u,b)\n",
    "    Jac_pre.append(temp)\n",
    "    \n",
    "  "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "df1 = pd.DataFrame(zip(pop_pre,Jac_pre))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math as mt\n",
    "def cosine(s1, s2):\n",
    "    numer = len(s1.intersection(s2))\n",
    "    l1=len(s1)\n",
    "    l2=len(s2)\n",
    "    denom = mt.sqrt(l1) * mt.sqrt(l2)\n",
    "    if denom > 0:\n",
    "        return numer/denom\n",
    "    return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mostSimilarcosine(u,b):\n",
    "    similarities_ = []   \n",
    "    #b1- all users who have read b\n",
    "    users_ = usersPerBook[b]\n",
    "    \n",
    "    #b1- all books read by user u\n",
    "   \n",
    "    for i2 in booksPerUser[u]:\n",
    "        if i2 == b: continue\n",
    "        sim_ = cosine(users_, usersPerBook[i2])\n",
    "        similarities_.append((sim_))\n",
    "    similarities_.sort(reverse=True)\n",
    "    \n",
    "    for x in similarities_[:1]:\n",
    "        if x > 0:\n",
    "            return x\n",
    "    return 0\n",
    "                            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "cos_pre = []\n",
    "for u,b,_ in total_train:\n",
    "    temp = mostSimilarcosine(u,b)\n",
    "    cos_pre.append(temp)\n",
    "    \n",
    "  "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "df2 = pd.DataFrame(zip(pop_pre,Jac_pre,cos_pre))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Jaccard(s1, s2):\n",
    "    numer = len(s1.intersection(s2))\n",
    "    denom = len(s1.union(s2))\n",
    "    if denom > 0:\n",
    "        return numer/denom\n",
    "    return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mostSimilarFast_items(u,b):\n",
    "    simil = []   \n",
    "    #b1- all books read by user u \n",
    "    books = set(ratingsPerUser[u])\n",
    "    \n",
    "    for i2 in ratingsPerItem[b]:\n",
    "        if i2 == u: continue\n",
    "        sim = Jaccard(books, set(ratingsPerUser[i2]))\n",
    "        simil.append((sim))\n",
    "    simil.sort(reverse=True)\n",
    "    for x in simil[:1]:\n",
    "        if x > 0 :\n",
    "            return x\n",
    "    return 0\n",
    "                       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "Jac2_pre = []\n",
    "for u,b,_ in total_train:\n",
    "    temp = mostSimilarFast_items(u,b)\n",
    "    Jac2_pre.append(temp)\n",
    "    "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "df3 = pd.DataFrame(zip(pop_pre,Jac_pre,cos_pre,Jac2_pre))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "## adding length of ratings\n",
    "\n",
    "lenR = []\n",
    "for u,b,_ in total_train:\n",
    "    te=0\n",
    "    temp = len(ratingsPerItem[b])\n",
    "    if temp > te :\n",
    "        lenR.append(temp)\n",
    "    else:\n",
    "        lenR.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4 = pd.DataFrame(zip(pop_pre,Jac_pre,cos_pre,Jac2_pre,lenR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df5 = pd.DataFrame(zip(Jac_pre,cos_pre,Jac2_pre,lenR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "df8= pd.DataFrame(zip(Jac2_pre,lenR))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "df9 = pd.DataFrame(zip(cos_pre,Jac2_pre,lenR))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "df6 = pd.DataFrame(zip(pop_pre,Jac_pre,cos_pre,Jac2_pre,lenR,avgR))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "df7 = pd.DataFrame(zip(Jac_pre,cos_pre,Jac2_pre,lenR,avgR))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "col_mask=df6.isnull().any(axis=0) "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "row_mask=df6.isnull().any(axis=1)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "df7.loc[row_mask,col_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = df8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = [d[2] for d in total_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "model = linear_model.LogisticRegression(C=0.00003)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=3e-05, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def total(v):\n",
    "    total_comp=[]\n",
    "    #print(v)\n",
    "    h = mostSimilarFast(v[0],v[1])\n",
    "    c = mostSimilarcosine(v[0],v[1])\n",
    "    i = mostSimilarFast_items(v[0],v[1])\n",
    "\n",
    "    \n",
    "    if v[1] in return1:\n",
    "        r = 1\n",
    "    else:\n",
    "        r = 0\n",
    "        \n",
    "    temp = len(ratingsPerItem[v[1]])\n",
    "    if temp > 0 :\n",
    "        j = temp\n",
    "    else:\n",
    "        j = 0\n",
    "        \n",
    "    #s=0\n",
    "    #for u,r in ratingsPerItem[v[1]]:\n",
    "       #s+= r\n",
    "    #if s > 0 and temp > 0 :\n",
    "        #a = s/temp\n",
    "    #else:\n",
    "        #a =0\n",
    "        \n",
    "    #total_comp.append(v[0])\n",
    "    #total_comp.append(v[1])\n",
    "    total_comp.append(r)\n",
    "    total_comp.append(h)\n",
    "    total_comp.append(c)\n",
    "    total_comp.append(i)\n",
    "    total_comp.append(j)\n",
    "    #total_comp.append(a)\n",
    "    return total_comp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "v_reg =[total(k) for k in total_valid]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature(d):\n",
    "    feat = [d[3],d[4]]\n",
    "    return feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_valid = [feature(d) for d in v_reg]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_valid = [d[2] for d in total_valid]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(x_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = pred == y_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6555"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# accuracy\n",
    "sum(correct) / len(correct)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making predictions on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_predict\n",
    "test_pop_pre = []\n",
    "test_jac_pre =[]\n",
    "test_cos_pre= []\n",
    "test_jac2_pre= []\n",
    "\n",
    "test_len =[]\n",
    "\n",
    "predictions = open(\"predictions_Read.txt\", 'w')\n",
    "for l in open(\"pairs_Read.txt\"):\n",
    "    if l.startswith(\"userID\"):continue\n",
    "    \n",
    "    u,b = l.strip().split('-')\n",
    "    \n",
    "    if b in return1:\n",
    "        test_pop_pre.append(1)\n",
    "    else:\n",
    "        test_pop_pre.append(0)\n",
    "          \n",
    "    t1 = mostSimilarFast(u,b)\n",
    "    test_jac_pre.append(t1) \n",
    "        \n",
    "    \n",
    "    t2 = mostSimilarcosine(u,b)\n",
    "    test_cos_pre.append(t2)\n",
    "    \n",
    "    t3 = mostSimilarFast_items(u,b)\n",
    "    test_jac2_pre.append(t3)\n",
    "    \n",
    "    \n",
    "    temp = len(usersPerBook[b])\n",
    "    if temp > 0 :\n",
    "        test_len.append(temp)\n",
    "    else:\n",
    "        test_len.append(0)\n",
    "    \n",
    "    \n",
    "        \n",
    "df_test = pd.DataFrame(zip(test_pop_pre,test_jac_pre,test_cos_pre,test_jac2_pre,test_len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test= model.predict(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob1= model.predict_proba(df_test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "ub5dict = defaultdict(list)\n",
    "\n",
    "userSet1 = set()\n",
    "\n",
    "k=0\n",
    "for l in open(\"pairs_Read.txt\"):\n",
    "    if l.startswith(\"userID\"):\n",
    "        continue\n",
    "    u,b = l.strip().split('-')\n",
    "    \n",
    "    p=prob1[k]\n",
    "    ub5dict[u].append((p,b))\n",
    "    userSet1.add(u)\n",
    "    k+=1\n",
    "\n",
    "userlist1 = list(userSet1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank = defaultdict(list)\n",
    "for u in userlist1:\n",
    "    ub5dict[u].sort()\n",
    "    ub5dict[u].reverse()\n",
    "    l=len(ub5dict[u])\n",
    "    i=0\n",
    "    for p,b in ub5dict[u]:\n",
    "        if i < l/2 :\n",
    "            rank[u].append((b,1))\n",
    "        else:\n",
    "            rank[u].append((b,0))\n",
    "        i +=1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "predictions = open(\"predictions_Read.txt\", 'w')\n",
    "for l in open(\"pairs_Read.txt\"):\n",
    "    if l.startswith(\"userID\"):\n",
    "    #header\n",
    "        predictions.write(l)\n",
    "        continue\n",
    "    u,b = l.strip().split('-')\n",
    "    \n",
    "    for b1,p in rank[u]:\n",
    "        if b1 == b:\n",
    "            predictions.write(u + '-' + b + \",\"+str(p)+\"\\n\")\n",
    "\n",
    "    \n",
    "predictions.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
