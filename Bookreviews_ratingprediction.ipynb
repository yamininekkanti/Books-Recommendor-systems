{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "from collections import defaultdict\n",
    "import scipy\n",
    "import scipy.optimize\n",
    "import numpy\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readCSV(path):\n",
    "  f = gzip.open(path, 'rt')\n",
    "  f.readline()\n",
    "  for l in f:\n",
    "    yield l.strip().split(',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "train =[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "for l in readCSV(\"train_Interactions.csv.gz\"):\n",
    "     train.append(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "#random.shuffle(train)\n",
    "dataset_valid = train[190000:]\n",
    "dataset_train = train[:190000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['u79354815', 'b14275065', '4']"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "usersPerBook = defaultdict(list)\n",
    "booksPerUser = defaultdict(list)\n",
    "ratingsPerUser = defaultdict(list)\n",
    "ratingsPerBook = defaultdict(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in dataset_train :\n",
    "    user = d[0]\n",
    "    book = d[1]\n",
    "    rating = int(d[2])\n",
    "    usersPerBook[book].append(user)\n",
    "    booksPerUser[user].append(book)\n",
    "    ratingsPerUser[user].append(rating)\n",
    "    ratingsPerBook[book].append(rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(usersPerBook['b13623045'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def srating(ratingsPerUser,u):\n",
    "    s=0\n",
    "    for e in ratingsPerUser[u]:\n",
    "        s += int(e)\n",
    "        \n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ratingMean = sum(int(d[2]) for d in dataset_train) / len(dataset_train)\n",
    "alpha = ratingMean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "userBiases = defaultdict(float)\n",
    "bookBiases = defaultdict(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MSE(predictions, labels):\n",
    "    differences = [(x-y)**2 for x,y in zip(predictions,labels)]\n",
    "    return sum(differences) / len(differences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def prediction(user, book,userBiases,bookBiases):\n",
    "    return alpha + userBiases[user] + bookBiases[book]\n",
    "\n",
    "def cost(userBiases,bookBiases,labels, lamb):\n",
    "    predictions = [prediction(d[0], d[1],userBiases,bookBiases) for d in dataset_train]\n",
    "    \n",
    "    cost = MSE(predictions, labels)\n",
    "    a=cost\n",
    "    print(\"MSE = \" + str(cost))\n",
    "    for u in userBiases:\n",
    "        cost += lamb*userBiases[u]**2\n",
    "    for i in bookBiases:\n",
    "        cost += lamb*bookBiases[i]**2\n",
    "    return a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Fitting the predictor for lambda =1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE = 0.9357391107718275\n",
      "MSE = 0.9286870528352935\n",
      "MSE = 0.9279491396128474\n",
      "MSE = 0.9277753325664596\n",
      "MSE = 0.9277068350048915\n",
      "MSE = 0.9276694959628146\n",
      "MSE = 0.9276447436458912\n",
      "MSE = 0.9276263594961619\n",
      "MSE = 0.9276118106089392\n",
      "MSE = 0.9275998918331229\n",
      "MSE = 0.9275899410526893\n",
      "MSE = 0.9275815431886733\n",
      "MSE = 0.9275744087753931\n",
      "MSE = 0.9275683204026712\n",
      "MSE = 0.9275631070681037\n",
      "MSE = 0.9275586305868406\n",
      "MSE = 0.9275547775261481\n",
      "MSE = 0.9275514538794956\n",
      "MSE = 0.9275485812465135\n",
      "MSE = 0.9275460939350189\n",
      "MSE = 0.9275439366884799\n",
      "MSE = 0.9275420628684343\n",
      "MSE = 0.9275404329844417\n",
      "MSE = 0.9275390134972087\n",
      "MSE = 0.9275377758389273\n",
      "MSE = 0.9275366956090286\n",
      "MSE = 0.9275357519113228\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "labels = [int(d[2]) for d in dataset_train]\n",
    "\n",
    "##initialization    \n",
    "\n",
    "alpha =  ratingMean\n",
    "\n",
    "for u in booksPerUser:\n",
    "    userBiases[u] = ((srating(ratingsPerUser,u))/(len(ratingsPerUser[u])))-ratingMean\n",
    "    \n",
    "for i in usersPerBook:\n",
    "    bookBiases[i] = ((srating(ratingsPerBook,i))/(len(ratingsPerBook[i])))-ratingMean\n",
    "\n",
    "prev_value = float('inf')\n",
    "\n",
    "lamb = 4\n",
    "\n",
    "alphadiff =0\n",
    "sumR = 0\n",
    "diffterm =0\n",
    "N = len(dataset_train)\n",
    "\n",
    "old_mse = 1\n",
    "counter = 0\n",
    "while(True):\n",
    "\n",
    "    alphadiff = 0\n",
    "    for d in dataset_train:\n",
    "        u = d[0]\n",
    "        i = d[1]\n",
    "        R = int(d[2])\n",
    "\n",
    "        alphadiff += (R-userBiases[u]-bookBiases[i])\n",
    "    alpha = (alphadiff)/N\n",
    "\n",
    "\n",
    "        ##BETA U    \n",
    "    for u in userBiases:\n",
    "        sumR = srating(ratingsPerUser,u)\n",
    "        diffterm = 0\n",
    "        for i in booksPerUser[u]:\n",
    "            diffterm += alpha+bookBiases[i]\n",
    "        diff = sumR - diffterm\n",
    "        userBiases[u] = float(diff)/((len(booksPerUser[u]) + lamb))\n",
    "\n",
    "\n",
    "        ##BETA I\n",
    "    for i in bookBiases: \n",
    "        sumR = srating(ratingsPerBook,i)\n",
    "        diffterm = 0\n",
    "        for u in usersPerBook[i]: \n",
    "            diffterm += (alpha+userBiases[u])\n",
    "        diff = sumR - diffterm\n",
    "        bookBiases[i]= float(diff)/(len(usersPerBook[i]) + lamb)\n",
    "\n",
    "\n",
    "    mse = cost(userBiases,bookBiases,labels,lamb)\n",
    "    #print(\"alpha:\", alpha)\n",
    "\n",
    "\n",
    "    if (old_mse-mse) <= 0.000001:\n",
    "        break\n",
    "    else :\n",
    "        old_mse = mse\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid_MSE 1.108786213061298\n"
     ]
    }
   ],
   "source": [
    "predict= []\n",
    "for d in dataset_valid:\n",
    "    user = d[0]\n",
    "    book = d[1]\n",
    "    R = int(d[2])\n",
    "    r = prediction(user,book,userBiases,bookBiases)\n",
    "    predict.append(r) \n",
    "\n",
    "y_values = [int(d[2]) for d in dataset_valid]\n",
    "valid_mse = MSE(predict,  y_values)\n",
    "print(\"Valid_MSE\",valid_mse )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Finding largest and smallest values of beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(-0.2405068945977436, 'b85536634'),\n",
       " (0.28568050540038126, 'b96213089'),\n",
       " (0.5310958145800748, 'b82936372')]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "beta_B = [(bookBiases[b], b) for b in bookBiases]\n",
    "beta_B[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-1.7890416452006146, 'b84091840')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beta_B.sort()\n",
    "negbeta_B = beta_B[0]\n",
    "negbeta_B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.1756118796622286, 'b19925500')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beta_B.reverse()\n",
    "posbeta_B = beta_B[0]\n",
    "posbeta_B "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Book with greater negative value of beta is b84091840. Book with greater positive value of beta is b19925500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_U = [(userBiases[u], u) for u in userBiases]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-3.778275374636964, 'u48313610')"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beta_U.sort()\n",
    "negbeta_U = beta_U[0]\n",
    "negbeta_U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.3287494174920815, 'u48167710')"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beta_U.reverse()\n",
    "posbeta_U = beta_U[0]\n",
    "posbeta_U "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "User with greater negative value of beta is u80513837. User with greater positive value of beta is u48167710 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Finding better value of lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost(userBiases,bookBiases,labels, lamb):\n",
    "    predictions = [prediction(d[0], d[1],userBiases,bookBiases) for d in dataset_train]\n",
    "    \n",
    "    cost = MSE(predictions, labels)\n",
    "    a=cost\n",
    "    #print(\"MSE = \" + str(cost))\n",
    "    for u in userBiases:\n",
    "        cost += lamb*userBiases[u]**2\n",
    "    for i in bookBiases:\n",
    "        cost += lamb*bookBiases[i]**2\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lamba  0.001\n",
      "MSE = 0.9080603499507711\n",
      "MSE = 0.9040204717610901\n",
      "MSE = 0.9035548684740015\n",
      "MSE = 0.9034290244712353\n",
      "MSE = 0.9033866626100694\n",
      "MSE = 0.9033715850600921\n",
      "MSE = 0.9033661278594212\n",
      "MSE = 0.9033641397647996\n",
      "MSE = 0.9033634125206206\n",
      "Valid_MSE 1.0818490304127444\n",
      "lamba  0.01\n",
      "MSE = 0.9080840495103893\n",
      "MSE = 0.904026759499787\n",
      "MSE = 0.9035577366560468\n",
      "MSE = 0.9034308114878115\n",
      "MSE = 0.9033879155438456\n",
      "MSE = 0.9033725100157434\n",
      "MSE = 0.903366840465744\n",
      "MSE = 0.9033647153835761\n",
      "MSE = 0.9033639011320657\n",
      "Valid_MSE 1.0816620849062084\n",
      "lamba  0\n",
      "MSE = 0.9080577410638572\n",
      "MSE = 0.9040198037873162\n",
      "MSE = 0.9035545824544984\n",
      "MSE = 0.903428859433095\n",
      "MSE = 0.9033865574137799\n",
      "MSE = 0.9033715166484891\n",
      "MSE = 0.903366083286035\n",
      "MSE = 0.9033641105841043\n",
      "MSE = 0.9033633931261859\n",
      "Valid_MSE 1.0818698801533198\n",
      "lamba  1\n",
      "MSE = 0.9126449188106961\n",
      "MSE = 0.9071587490840035\n",
      "MSE = 0.9064597212196943\n",
      "MSE = 0.9062719030301315\n",
      "MSE = 0.9062021168192123\n",
      "MSE = 0.9061711415345614\n",
      "MSE = 0.9061557409017105\n",
      "MSE = 0.9061474208230353\n",
      "MSE = 0.9061425875270366\n",
      "MSE = 0.9061395625408475\n",
      "MSE = 0.9061375100780296\n",
      "MSE = 0.9061359971045907\n",
      "MSE = 0.9061347937104641\n",
      "MSE = 0.9061337758542596\n",
      "MSE = 0.9061328757569568\n",
      "Valid_MSE 1.067190982948088\n",
      "lamba  10\n",
      "MSE = 0.996201279216457\n",
      "MSE = 0.9884885303181565\n",
      "MSE = 0.9878820516892375\n",
      "MSE = 0.9877121723329564\n",
      "MSE = 0.987622307972066\n",
      "MSE = 0.9875643257084781\n",
      "MSE = 0.9875243232818354\n",
      "MSE = 0.9874958846154847\n",
      "MSE = 0.9874753129900239\n",
      "MSE = 0.9874602540628473\n",
      "MSE = 0.9874491318384507\n",
      "MSE = 0.9874408599946631\n",
      "MSE = 0.9874346743737096\n",
      "MSE = 0.9874300289247965\n",
      "MSE = 0.9874265284282306\n",
      "MSE = 0.987423883799331\n",
      "MSE = 0.9874218817469407\n",
      "MSE = 0.987420363791378\n",
      "MSE = 0.987419211512965\n",
      "MSE = 0.9874183360297584\n",
      "Valid_MSE 1.083458032713087\n"
     ]
    }
   ],
   "source": [
    "#userBiases = defaultdict(float)\n",
    "#bookBiases = defaultdict(float)\n",
    "\n",
    "L=[0.001,0.01,0,1,10]\n",
    "\n",
    "for lm in L:\n",
    "    userBiases = defaultdict(float)\n",
    "    bookBiases = defaultdict(float)\n",
    "    print(\"lamba \", lm)\n",
    "    labels = [int(d[2]) for d in dataset_train]\n",
    "\n",
    "    ##initialization    \n",
    "\n",
    "    alpha =  ratingMean\n",
    "\n",
    "    for u in booksPerUser:\n",
    "        userBiases[u] = ((srating(ratingsPerUser,u))/(len(ratingsPerUser[u])))-ratingMean\n",
    "\n",
    "    for i in usersPerBook:\n",
    "        bookBiases[i] = ((srating(ratingsPerBook,i))/(len(ratingsPerBook[i])))-ratingMean\n",
    "\n",
    "\n",
    "    lamb = lm\n",
    "\n",
    "    alphadiff =0\n",
    "    sumR = 0\n",
    "    diffterm =0\n",
    "    N = len(dataset_train)\n",
    "\n",
    "    old_mse = 1\n",
    "    counter = 0\n",
    "    while(True):\n",
    "\n",
    "        alphadiff = 0\n",
    "        for d in dataset_train:\n",
    "            u = d[0]\n",
    "            i = d[1]\n",
    "            R = int(d[2])\n",
    "\n",
    "            alphadiff += (R-userBiases[u]-bookBiases[i])\n",
    "        alpha = (alphadiff)/N\n",
    "\n",
    "\n",
    "            ##BETA U    \n",
    "        for u in userBiases:\n",
    "            sumR = srating(ratingsPerUser,u)\n",
    "            diffterm = 0\n",
    "            for i in booksPerUser[u]:\n",
    "                diffterm += alpha+bookBiases[i]\n",
    "            diff = sumR - diffterm\n",
    "            userBiases[u] = float(diff)/((len(booksPerUser[u]) + lamb))\n",
    "\n",
    "\n",
    "            ##BETA I\n",
    "        for i in bookBiases: \n",
    "            sumR = srating(ratingsPerBook,i)\n",
    "            diffterm = 0\n",
    "            for u in usersPerBook[i]: \n",
    "                diffterm += (alpha+userBiases[u])\n",
    "            diff = sumR - diffterm\n",
    "            bookBiases[i]= float(diff)/(len(usersPerBook[i]) + lamb)\n",
    "\n",
    "\n",
    "        mse = cost(userBiases,bookBiases,labels,lamb)\n",
    "        #print(\"alpha:\", alpha)\n",
    "         \n",
    "\n",
    "        if (old_mse-mse) <= 0.000001:\n",
    "            \n",
    "            predict= []\n",
    "            for d in dataset_valid:\n",
    "                user = d[0]\n",
    "                book = d[1]\n",
    "                R = int(d[2])\n",
    "                r = prediction(user,book,userBiases,bookBiases)\n",
    "                predict.append(r) \n",
    "\n",
    "            y_values = [int(d[2]) for d in dataset_valid]\n",
    "            valid_mse = MSE(predict,  y_values)\n",
    "            print(\"Valid_MSE\",valid_mse )\n",
    "            \n",
    "            break\n",
    "        else :\n",
    "            old_mse = mse\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictinf the ratings\n",
    "lambda = 1 yields better error rate for the validation set. MSE of validation set for lambda=1 is 1.1191\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = open(\"predictions_Rating.txt\", 'w')\n",
    "for l in open(\"pairs_Rating.txt\"):\n",
    "    if l.startswith(\"userID\"):\n",
    "    #header\n",
    "        predictions.write(l)\n",
    "        continue\n",
    "    u,b = l.strip().split('-')\n",
    "    #x=str(u)\n",
    "    #print(x)\n",
    "    #if user in userBiases and book in bookBiases :\n",
    "    r = prediction(u,b,userBiases,bookBiases)\n",
    "    #else:\n",
    "        #r=0\n",
    "    predictions.write(u + '-' + b + ',' + str(r) + '\\n')\n",
    "predictions.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
